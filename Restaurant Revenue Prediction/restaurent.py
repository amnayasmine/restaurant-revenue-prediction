# -*- coding: utf-8 -*-
"""restaurent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_nYAyg3vadrwc9ptPHC-kgSTKO7gvfSt

#RESTAURANT REVENUE PREDICTION

#INTRODUCTION

The restaurant industry is highly competitive, with numerous factors influencing business success. This project aims to analyze key attributes such as pricing, customer engagement, service quality, and marketing strategies to understand their impact on restaurant revenue. By leveraging data-driven insights,  restaurant owners can make  decisions regarding pricing, marketing budgets, and operational improvements. Additionally, we explore predictive modeling techniques to estimate restaurant revenue based on various attributes.

#DATASET

This dataset contains information about various restaurants and aims to predict the revenue based on several features. Each row represents a unique restaurant with various attributes that may influence its revenue.

Columns


* Name: The name of the restaurant.

* Location: The location of the restaurant (e.g., Rural, Downtown).

* Cuisine: The type of cuisine offered (e.g., Japanese, Mexican, Italian).

* Rating: The average rating of the restaurant.

* Seating Capacity: The number of seats available in the restaurant.

* Average Meal Price: The average price of a meal at the restaurant.

* Marketing Budget: The marketing budget allocated for the restaurant.

* Social Media Followers: The number of social media followers.

* Chef Experience Years: The number of years of experience of the head chef.

* Number of Reviews: The total number of reviews the restaurant has received.

* Avg Review Length: The average length of reviews.

* Ambience Score: A score representing the ambience of the restaurant.

* Service Quality Score: A score representing the quality of service.

* Parking Availability: Indicates if parking is available (Yes/No).

* Weekend Reservations: The number of reservations made on weekends.

* Weekday Reservations: The number of reservations made on weekdays.

* Revenue: The total revenue generated by the restaurant.
"""

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Data Science/Projects/ML Project/restaurant_data.csv')

"""#PREPROCESSING"""

df.head()

df.tail()

df.shape

df.size

df.columns

# Rename the columns
df = df.rename(columns={
    'Seating Capacity': 'Seating_Capacity',
    'Average Meal Price': 'Average_Meal_Price',
    'Marketing Budget': 'Marketing_Budget',
    'Social Media Followers': 'Social_Media_Followers',
    'Chef Experience Years': 'Chef_Experience_Years',
    'Number of Reviews': 'Number_of_Reviews',
    'Avg Review Length': 'Avg_Review_Length',
    'Ambience Score': 'Ambience_Score',
    'Service Quality Score': 'Service_Quality_Score',
    'Parking Availability': 'Parking_Availability',
    'Weekend Reservations': 'Weekend_Reservations',
    'Weekday Reservations': 'Weekday_Reservations',
})

df.ndim

df.info()

df.describe()

df.isna().sum()

df.duplicated().sum()

df.head()

df.drop(['Name'],axis=1,inplace=True)



"""#OUTLIER"""

# outlier checking
import seaborn as sns
import matplotlib.pyplot as plt
for i in df.columns:
  sns.boxplot(x = df[i])
  plt.show()
  print(i,'*'*100)

"""#VISUALIZATION"""

plt.figure(figsize=(5,5))
sns.barplot(data=df, x='Location', y='Revenue',facecolor = 'skyblue',width = 0.5)
plt.title('Location vs. Revenue')
plt.xlabel('Location')
plt.ylabel('Revenue')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

plt.figure(figsize=(5,5))
plt.scatter(df['Cuisine'], df['Revenue'])
plt.xlabel('Cuisine')
plt.ylabel('Revenue')
plt.title('Scatter Plot of Revenue by Cuisine')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(5, 5))
sns.histplot(df["Seating_Capacity"], bins=30, kde=True)
plt.title("Distribution of Seating Capacity")
plt.xlabel("Seating Capacity")
plt.ylabel("Number of Restaurants")
plt.show()

"""#ENCODING"""

column_name = df.columns
for i in column_name:
  print(df[i].value_counts(),i)
  print('*'*100)

df.info()

df['Location'].unique()

from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder(sparse_output=False)
encoder.fit(df[['Location']])
ohe = encoder.transform(df[['Location']])

df1 = pd.DataFrame(ohe,columns=encoder.get_feature_names_out(['Location']))

df['Cuisine'].unique()

from sklearn.preprocessing import OneHotEncoder
encoder1 = OneHotEncoder(sparse_output=False)
encoder1.fit(df[['Cuisine']])
ohe1 = encoder1.transform(df[['Cuisine']])

df2 = pd.DataFrame(ohe1,columns=encoder1.get_feature_names_out(['Cuisine']))

df['Parking_Availability'].unique()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(df['Parking_Availability'])
df['Parking_Availability'] = le.transform(df['Parking_Availability'])

df = pd.concat([df,df1,df2],axis=1)

df.drop(['Location','Cuisine'],axis = 1,inplace = True)

df.head()

df.info()



"""#CORRELATION MATRIX"""

mtx = df.corr()
mtx

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 8))
sns.heatmap(mtx,annot=True,fmt = '0.1f')
plt.show()

mtx1 = df.corr()['Revenue']
mtx1

plt.figure(figsize=(5,5))
sns.heatmap(df[['Seating_Capacity','Average_Meal_Price','Marketing_Budget','Social_Media_Followers','Weekend_Reservations','Weekday_Reservations','Revenue']].corr(),annot=True,fmt = '0.1f',cmap='Blues')

df.drop(['Rating', 'Number_of_Reviews', 'Avg_Review_Length', 'Parking_Availability'],axis = 1,inplace = True)

df.head()

df.shape



"""#MODEL"""

x = df.drop('Revenue',axis = 1)
y = df['Revenue']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42 )

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from sklearn import metrics
import numpy as np

"""#KNN"""

from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor()

knn.get_params()

help(knn)

knn_params = {
    "n_neighbors": [ 3,5,7,9],
    "weights": ["uniform", "distance"],
    "metric": ["euclidean", "manhattan","minkowski"],
}
knn_grid = GridSearchCV(knn,knn_params,cv = 5,scoring = 'r2')
knn_grid.fit(x_train,y_train)

print('Best Parameters : ',knn_grid.best_params_)
print('Best Score : ',knn_grid.best_score_)

knn1 = KNeighborsRegressor(n_neighbors=9, weights='distance', metric='manhattan')
knn1.fit(x_train,y_train)

ypred_knn = knn1.predict(x_test)
ypred_knn

from sklearn.metrics import r2_score
r2_score_knn = r2_score(y_test,ypred_knn)
print('R2 Score : ',r2_score_knn)

from sklearn.metrics import mean_absolute_error,mean_squared_error,root_mean_squared_error
mae_knn = mean_absolute_error(y_test,ypred_knn)
mse_knn = mean_squared_error(y_test,ypred_knn)
rmse_knn = root_mean_squared_error(y_test,ypred_knn)
print('mean_absolute_error : ',mae_knn)
print('mean_squared_error : ',mse_knn)
print('root_mean_squared_error : ',rmse_knn)

print('Training Score : ',knn1.score(x_train,y_train))
print('Testing Score : ',knn1.score(x_test,y_test))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_test, y=ypred_knn, color='blue', alpha=0.6, label="Predicted vs Actual")
# Perfect prediction line
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--", label="Perfect Fit")

plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("KNN: Actual vs. Predicted Calories")
plt.legend()
plt.show()

"""#LINEAR REGRESSION"""

from sklearn.linear_model import LinearRegression
lr = LinearRegression()

lr.get_params()

help(lr)

import warnings
warnings.filterwarnings('ignore')

lr_params = {
    'fit_intercept': [True, False],
    'copy_X': [True, False],
    'positive': [True, False]
}
lr_grid = GridSearchCV(lr,lr_params,cv = 5,scoring = 'r2')
lr_grid.fit(x_train,y_train)

print('Best Parameters : ',lr_grid.best_params_)
print('Best Score : ',lr_grid.best_score_)

lr1 = LinearRegression(copy_X=True, fit_intercept=True, positive=True)
lr1.fit(x_train,y_train)

ypred_lr = lr1.predict(x_test)
ypred_lr

from sklearn.metrics import r2_score
r2_score_lr = r2_score(y_test,ypred_lr)
print('R2 Score : ',r2_score_lr)

from sklearn.metrics import mean_absolute_error,mean_squared_error,root_mean_squared_error
mae_lr = mean_absolute_error(y_test,ypred_lr)
mse_lr = mean_squared_error(y_test,ypred_lr)
rmse_lr = root_mean_squared_error(y_test,ypred_lr)
print('mean_absolute_error : ',mae_lr)
print('mean_squared_error : ',mse_lr)
print('root_mean_squared_error : ',rmse_lr)

print('Training Score : ',lr1.score(x_train,y_train))
print('Testing Score : ',lr1.score(x_test,y_test))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_test, y=ypred_lr, color='blue', alpha=0.6, label="Predicted vs Actual")
# Perfect prediction line
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--", label="Perfect Fit")

plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("LINEAR REGRESSION: Actual vs. Predicted Calories")
plt.legend()
plt.show()

"""#DECISION TREE"""

from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeRegressor()

dt.get_params()

help(dt)

dt_params = {
    "criterion": ["squared_error", "friedman_mse", "absolute_error", "poisson"],
    "splitter": ["best", "random"],
     "max_depth": [5, 10, 20],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
}
dt_grid = GridSearchCV(dt,dt_params,cv = 5,scoring = 'r2')
dt_grid.fit(x_train,y_train)

print('Best Parameters : ',dt_grid.best_params_)
print('Best Score : ',dt_grid.best_score_)

dt1 = DecisionTreeRegressor(criterion='poisson', max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter='best')
dt1.fit(x_train,y_train)

ypred_dt = dt1.predict(x_test)
ypred_dt

from sklearn.metrics import r2_score
r2_score_dt = r2_score(y_test,ypred_dt)
print('R2 Score : ',r2_score_dt)

from sklearn.metrics import mean_absolute_error,mean_squared_error,root_mean_squared_error
mae_dt = mean_absolute_error(y_test,ypred_dt)
mse_dt = mean_squared_error(y_test,ypred_dt)
rmse_dt = root_mean_squared_error(y_test,ypred_dt)
print('mean_absolute_error : ',mae_dt)
print('mean_squared_error : ',mse_dt)
print('root_mean_squared_error : ',rmse_dt)

print('Training Score : ',dt1.score(x_train,y_train))
print('Testing Score : ',dt1.score(x_test,y_test))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_test, y=ypred_dt, color='blue', alpha=0.6, label="Predicted vs Actual")
# Perfect prediction line
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--", label="Perfect Fit")

plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("DECISION TREE: Actual vs. Predicted Calories")
plt.legend()
plt.show()

"""#SVM"""

from sklearn.svm import SVR
svm = SVR()

svm.get_params()

help(svm)

svm_params = {
    "kernel": ["linear", "poly", "rbf", "sigmoid"],
    "degree": [2, 3, 4],
    "gamma": ["scale", "auto"],
    "C": [0.1, 1, 10],
    "epsilon": [0.1, 0.5, 1],
}
svm_grid = GridSearchCV(svm,svm_params,cv = 5,scoring = 'r2')
svm_grid.fit(x_train,y_train)

print('Best Parameters : ',svm_grid.best_params_)
print('Best Score : ',svm_grid.best_score_)

svm1 = SVR(C=10, degree=2, epsilon=0.1, gamma='scale', kernel='linear')
svm1.fit(x_train,y_train)

ypred_svm = svm1.predict(x_test)
ypred_svm

from sklearn.metrics import r2_score
r2_score_svm = r2_score(y_test,ypred_svm)
print('R2 Score : ',r2_score_svm)

from sklearn.metrics import mean_absolute_error,mean_squared_error,root_mean_squared_error
mae_svm = mean_absolute_error(y_test,ypred_svm)
mse_svm = mean_squared_error(y_test,ypred_svm)
rmse_svm = root_mean_squared_error(y_test,ypred_svm)
print('mean_absolute_error : ',mae_svm)
print('mean_squared_error : ',mse_svm)
print('root_mean_squared_error : ',rmse_svm)

print('Training Score : ',svm1.score(x_train,y_train))
print('Testing Score : ',svm1.score(x_test,y_test))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_test, y=ypred_svm, color='blue', alpha=0.6, label="Predicted vs Actual")
# Perfect prediction line
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--", label="Perfect Fit")

plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("SVM: Actual vs. Predicted Calories")
plt.legend()
plt.show()

"""#RANDOM FOREST"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()

rf.get_params()

help(rf)

rf_params = {
    "n_estimators": [100, 200, 300],
    "max_depth": [10, 15, 20],
    "min_samples_split": [2,5, 10],
    "min_samples_leaf": [1,2,4],
    'max_features': ['auto', 'sqrt', 'log2']
}
rf_grid = GridSearchCV(rf,rf_params,cv = 5,scoring = 'r2',n_jobs = -1)
rf_grid.fit(x_train,y_train)

print('Best Parameters : ',rf_grid.best_params_)
print('Best Score : ',rf_grid.best_score_)

rf1 = RandomForestRegressor(max_depth=20,max_features = 'sqrt',min_samples_leaf=1, min_samples_split=2, n_estimators=300,random_state = 42)
rf1.fit(x_train,y_train)

ypred_rf = rf1.predict(x_test)
ypred_rf

from sklearn.metrics import r2_score
r2_score_rf = r2_score(y_test,ypred_rf)
print('R2 Score : ',r2_score_rf)

from sklearn.metrics import mean_absolute_error,mean_squared_error,root_mean_squared_error
mae_rf = mean_absolute_error(y_test,ypred_rf)
mse_rf = mean_squared_error(y_test,ypred_rf)
rmse_rf = root_mean_squared_error(y_test,ypred_rf)
print('mean_absolute_error : ',mae_rf)
print('mean_squared_error : ',mse_rf)
print('root_mean_squared_error : ',rmse_rf)

print('Training Score : ',rf1.score(x_train,y_train))
print('Testing Score : ',rf1.score(x_test,y_test))

import matplotlib.pyplot as plt

feature_importances = rf1.best_estimator_.feature_importances_
features = df.drop(columns=["Revenue"]).columns  # Exclude target variable

plt.figure(figsize=(5,5))
plt.barh(features, feature_importances)
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Random Forest Feature Importance")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_test, y=ypred_rf, color='blue', alpha=0.6, label="Predicted vs Actual")
# Perfect prediction line
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--", label="Perfect Fit")

plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("RANDOM FOREST: Actual vs. Predicted Calories")
plt.legend()
plt.show()

"""#ADABOOST"""

from sklearn.ensemble import AdaBoostRegressor
ada = AdaBoostRegressor()

ada.get_params()

help(ada)

from random import randint, uniform

ada_params = {
    'n_estimators': [randint(1, 101)],
    'learning_rate': [uniform(0.01, 0.98)],
    'loss': ['linear', 'square', 'exponential'],
    'random_state': [randint(1, 43)]
}
ada_grid = GridSearchCV(ada, ada_params, cv=5, scoring='r2')
ada_grid.fit(x_train, y_train)

print('Best Parameters : ',ada_grid.best_params_)
print('Best Score : ',ada_grid.best_score_)

ada1=AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=20),learning_rate= 0.6408531408339623, loss= 'square', n_estimators= 75, random_state= 33)
ada1.fit(x_train,y_train)

ypred_ada = ada1.predict(x_test)
ypred_ada

from sklearn.metrics import r2_score
r2_score_ada = r2_score(y_test,ypred_ada)
print('R2 Score : ',r2_score_ada)

from sklearn.metrics import mean_absolute_error,mean_squared_error,root_mean_squared_error
mae_ada = mean_absolute_error(y_test,ypred_ada)
mse_ada = mean_squared_error(y_test,ypred_ada)
rmse_ada = root_mean_squared_error(y_test,ypred_ada)
print('mean_absolute_error : ',mae_ada)
print('mean_squared_error : ',mse_ada)
print('root_mean_squared_error : ',rmse_ada)

print('Training Score : ',ada1.score(x_train,y_train))
print('Testing Score : ',ada1.score(x_test,y_test))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_test, y=ypred_ada, color='blue', alpha=0.6, label="Predicted vs Actual")
# Perfect prediction line
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--", label="Perfect Fit")

plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("ADABOOST: Actual vs. Predicted Calories")
plt.legend()
plt.show()

"""# Final"""

import pandas as pd
results = {
 "Model": ["KNN", "Linear Regression", "Decision Tree", "SVM", "Random Forest","Adaboost"],
 "R² Score": [r2_score_knn, r2_score_lr,r2_score_dt, r2_score_svm, r2_score_rf,r2_score_ada],
 "MAE": [mae_knn,mae_lr,mae_dt,mae_svm,mae_rf,mae_ada],
 "RMSE": [rmse_knn, rmse_lr,rmse_dt, rmse_svm,rmse_rf,rmse_ada]
 }
pd.DataFrame(results).sort_values(by="R² Score", ascending=False)

"""#SAV"""

import pickle
pickle.dump(ada1,open('model.sav','wb'))
pickle.dump(scaler,open('scaler.sav','wb'))
pickle.dump(encoder,open('EL.sav','wb'))
pickle.dump(encoder1,open('EC.sav','wb'))

pip list



"""#CONCLUSION

Through data exploration and analysis, we identified significant factors influencing restaurant revenue, such as pricing strategies, marketing efforts, and service quality. Our findings suggest that customer engagement, social media presence, and ambiance scores play a crucial role in attracting customers. By implementing predictive modeling, we can estimate revenue trends and provide valuable recommendations for restaurant owners. Future enhancements could include incorporating external factors like economic trends or seasonal effects to improve model accuracy.
"""